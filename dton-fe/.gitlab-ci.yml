image: docker.sinergise.com/team-6/dockercache/node:14-alpine

variables:
  WEBDEV_FTP_HOST: 'webdev1-ssh.sinergise.com'

stages:
  - test
  - deploy

### TEST: ###
install_packages_and_run_lint:
    stage: test
    script:
      - apk add --update git
      - npm ci
      - npm run lint
      # eslint makes sure that prettier was run on .js files, but it doesn't support .json files. To make sure thst JSON
      # was formatted properly we run prettier here and abort if any of the files have changed:
      - npm run prettier
      - git diff --exit-code HEAD -- '*.json' || (echo "Did you forget to run prettier?" && exit 1)
    artifacts:
      expire_in: 2 days
      paths:
        # we will need the installed packages in next step, so cache might not be enough - we need to create an artifact:
        - ./node_modules

### DEPLOY: ###
deploy_testing:
  stage: deploy
  variables:
    REACT_APP_BASENAME: '/tmp/digital-twin-news/$CI_COMMIT_REF_SLUG'
    REACT_APP_ROOT_URL: 'https://webdev.sentinel-hub.com/tmp/digital-twin-news/$CI_COMMIT_REF_SLUG/'
    REACT_APP_ANONYMOUS_AUTH_CLIENT_ID: $TEST_REACT_APP_ANONYMOUS_AUTH_CLIENT_ID
    REACT_APP_CAPTCHA_SITE_KEY: $TEST_REACT_APP_CAPTCHA_SITE_KEY
  except:
    - master
    - tags
  script:
    - apk add jq
    - echo "`jq --arg REACT_APP_ROOT_URL "$REACT_APP_ROOT_URL" '.homepage=$REACT_APP_ROOT_URL' package.json`" > package.json
    - CI=true npm run build
    - mv ./build ./build_testing
    - export TARGET_DIR="/sentinel/tmp/digital-twin-news/$CI_COMMIT_REF_SLUG/"
    - apk add --update ncftp
    - echo "rm -r $TARGET_DIR; mkdir $TARGET_DIR" | ncftp -u $WEBDEV_FTP_USERNAME -p $WEBDEV_FTP_PASSWORD $WEBDEV_FTP_HOST
    - ncftpput -m -u $WEBDEV_FTP_USERNAME -p $WEBDEV_FTP_PASSWORD -R $WEBDEV_FTP_HOST $TARGET_DIR ./build_testing/*
    - 'echo "Testing URL: $REACT_APP_ROOT_URL"'
  dependencies:
    - install_packages_and_run_lint
  environment:
    name: testing-$CI_COMMIT_REF_SLUG
    url: 'https://webdev.sentinel-hub.com/tmp/digital-twin-news/$CI_COMMIT_REF_SLUG/'

deploy_staging:
  stage: deploy
  variables:
    REACT_APP_BASENAME: '/digital-twin-news/'
    REACT_APP_ROOT_URL: 'https://webdev.sentinel-hub.com/digital-twin-news/'
    REACT_APP_ANONYMOUS_AUTH_CLIENT_ID: $TEST_REACT_APP_ANONYMOUS_AUTH_CLIENT_ID
    REACT_APP_CAPTCHA_SITE_KEY: $TEST_REACT_APP_CAPTCHA_SITE_KEY
  only:
    - master
  script:
    - apk add jq
    - echo "`jq --arg REACT_APP_ROOT_URL "$REACT_APP_ROOT_URL" '.homepage=$REACT_APP_ROOT_URL' package.json`" > package.json
    - CI=true npm run build
    - mv ./build ./build_staging
    - export TARGET_DIR="/sentinel/digital-twin-news/"
    - apk add --update ncftp
    - echo "rm -r $TARGET_DIR; mkdir $TARGET_DIR" | ncftp -u $WEBDEV_FTP_USERNAME -p $WEBDEV_FTP_PASSWORD $WEBDEV_FTP_HOST
    - ncftpput -m -u $WEBDEV_FTP_USERNAME -p $WEBDEV_FTP_PASSWORD -R $WEBDEV_FTP_HOST $TARGET_DIR ./build_staging/*
    - 'echo "Staging URL: $REACT_APP_ROOT_URL"'
  dependencies:
    - install_packages_and_run_lint
  environment:
    name: staging
    url: $REACT_APP_ROOT_URL

deploy_production:
  stage: deploy
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]+([-]rc[.][a-z0-9_-]+)?$/
  variables:
    S3_BUCKET_NAME: 'apps.sentinel-hub.com'
    S3_APP_NAME: 'digital-twin-news'
    REACT_APP_ANONYMOUS_AUTH_CLIENT_ID: $PROD_REACT_APP_ANONYMOUS_AUTH_CLIENT_ID
    REACT_APP_CAPTCHA_SITE_KEY: $PROD_REACT_APP_CAPTCHA_SITE_KEY
    AWS_REGION: eu-central-1
    AWS_ACCESS_KEY_ID: $PROD_AWS_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $PROD_AWS_SECRET_ACCESS_KEY
    AWS_CLOUDFRONT_DISTRIBUTION: $PROD_AWS_CLOUDFRONT_DISTRIBUTION
  script:
    - apk add --update python python-dev py-pip
    - pip install awscli
    - export REACT_APP_ROOT_URL="https://apps.sentinel-hub.com/$S3_APP_NAME/"
    - CI="" npm run build
    - mv ./build ./build_prod
    # deploy to AWS S3:
    - aws s3 sync ./build_prod s3://$S3_BUCKET_NAME/$S3_APP_NAME/
    - INVALIDATION_OUTPUT=$(aws cloudfront create-invalidation --distribution-id $AWS_CLOUDFRONT_DISTRIBUTION --paths "/$S3_APP_NAME/*" "/$S3_APP_NAME")
    - 'echo "INVALIDATION OUTPUT: $INVALIDATION_OUTPUT"'
    - INVALIDATION_ID=$(echo "$INVALIDATION_OUTPUT" | python -c "import sys, json; print json.load(sys.stdin)['Invalidation']['Id']")
    # wait for Cloudfront invalidation to run their course:
    - aws cloudfront wait invalidation-completed --distribution-id $AWS_CLOUDFRONT_DISTRIBUTION --id "$INVALIDATION_ID"
  dependencies:
    - install_packages_and_run_lint
  artifacts:
    expire_in: 100 years
    paths:
      - ./build_prod
  environment:
    name: production
    url: 'https://apps.sentinel-hub.com/digital-twin-news/'

# GITHUB
# Since we don't have a dedicated repository for combined DToN repositories in the internal GIT,
# we clone the repository with combined DToN repositories from GitHub to get .git folder from it.
# We clone DToN repositories from internal GIT to a group folder, 
# checkout their latest versions and remove their .git folders.
# Then we copy the .git folder from the dedicated repository for combined DToN repositories on GitHub 
# to the folder with newly cloned DToN repositories.
publish_github:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]+([.][^.]+)?$/
  before_script:
    - apk add --no-cache git openssh-client
  script:
    # prepare SSH credentials for cloning from GitHub:
    - mkdir -m 700 ~/.ssh
    - echo ${GITHUB_SSH_PRIVATE_KEY_BASE64} | base64 -d > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - echo ${GITHUB_SSH_KNOWN_HOST} > ~/.ssh/known_hosts

    # remove folder with cloned dton from github if it exists and clone it
    - test -d ../dton_gh && rm -r ../dton_gh
    - git clone git@github.com:sentinel-hub/digital-twin-of-news.git ../dton_gh
    # remove dton folder if it exists and create it anew
    - test -d ../dton && rm -r ../dton
    - mkdir ../dton
    # copy the .git folder from GitHub repository to the folder with cloned DToN repositories:
    - cp -r ../dton_gh/.git ../dton/
    - cd ../dton

    # clone DToN repositoris from internal GIT and remove their .git folders
    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@git.sinergise.com/team-6/dton/dton-fe.git ./dton-fe
    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@git.sinergise.com/team-6/dton/dton-event-processing.git ./dton-event-processing
    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@git.sinergise.com/team-6/dton/dton-api.git ./dton-api
    
    # checkout the latest tags
    - cd ./dton-fe
    - dtonFEtag=$(git describe --tags --abbrev=0)
    - git checkout ${dtonFEtag}
    - rm -r .git
    - cd ../dton-event-processing
    - dtonEPtag=$(git describe --tags --abbrev=0)
    - git checkout ${dtonEPtag}
    - rm -r .git
    - cd ../dton-api
    - dtonAPItag=$(git describe --tags --abbrev=0)
    - git checkout ${dtonAPItag}
    - rm -r .git
    - cd ..

    # commit and push new changes for repository with combined DToN repositories on GitHub
    - git add .
    - git status
    - git config --global user.email ${GITHUB_USER_EMAIL}
    - git config --global user.name ${GITHUB_USER_NAME}
    - versionTag=fe-${dtonFEtag}-ep-${dtonEPtag}-api-${dtonAPItag}
    - git commit -m "Update sources to version [${versionTag}]"
    - git tag ${versionTag}
    - git push --tags origin master

  after_script:
    # clean up in any case (if job succeeds or not)
    # remove dton and dton_gh folders if they exist
    - test -d ../dton && rm -r ../dton
    - test -d ../dton_gh && rm -r ../dton_gh
